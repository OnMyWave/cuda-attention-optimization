# Getting Started Guide

ì´ ê°€ì´ë“œëŠ” CUDA Attention Optimization í”„ë¡œì íŠ¸ë¥¼ ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´
- CUDA Toolkit 12.0 ì´ìƒ
- Python 3.10 ì´ìƒ
- PyTorch 2.0 ì´ìƒ (CUDA ì§€ì›)
- GCC/G++ ì»´íŒŒì¼ëŸ¬

### GPU ìš”êµ¬ì‚¬í•­
- NVIDIA GPU (Compute Capability 7.0 ì´ìƒ)
- ê¶Œì¥: V100, A100, RTX 3090, RTX 4090, H100

## ì„¤ì¹˜ ë‹¨ê³„

### 1. CUDA í™•ì¸

```bash
# CUDA ë²„ì „ í™•ì¸
nvcc --version

# CUDA ê²½ë¡œ ì„¤ì • (í•„ìš”í•œ ê²½ìš°)
export CUDA_HOME=/usr/local/cuda-12.4
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```

### 2. Python í™˜ê²½ ì„¤ì •

#### ë°©ë²• A: Conda ì‚¬ìš© (ê¶Œì¥)

```bash
# Conda í™˜ê²½ ìƒì„±
conda env create -f environment.yml
conda activate cuda-opt

# ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜
conda create -n cuda-opt python=3.10
conda activate cuda-opt
conda install pytorch pytorch-cuda=12.1 -c pytorch -c nvidia
conda install matplotlib numpy pytest
```

#### ë°©ë²• B: pip ì‚¬ìš©

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv
source venv/bin/activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
```

### 3. PyTorch CUDA í™•ì¸

```bash
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"
```

ì¶œë ¥ ì˜ˆì‹œ:
```
CUDA available: True
Device: NVIDIA A100-SXM4-40GB
```

## Phaseë³„ ì‹¤í–‰ ê°€ì´ë“œ

### Phase 1: PyTorch Baseline

```bash
cd phase1_baseline

# 1. Transformer ëª¨ë¸ í…ŒìŠ¤íŠ¸
python3 pytorch_transformer.py
# ì¶œë ¥: ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ê³  forward passê°€ ì™„ë£Œë¨

# 2. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
python3 profile_pytorch.py
# ì¶œë ¥: results/baseline_metrics.json ìƒì„±

# 3. ê²°ê³¼ ì‹œê°í™”
python3 visualize_results.py
# ì¶œë ¥: results/baseline_roofline.png, results/performance_comparison.png ìƒì„±
```

**ì˜ˆìƒ ê²°ê³¼:**
- ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ì™„ë£Œ
- GFLOPS, ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ê³„ì‚°
- Roofline í”Œë¡¯ ìƒì„±

### Phase 2: Naive CUDA Implementation

```bash
cd ../phase2_naive

# 1. CUDA extension ë¹Œë“œ
python3 setup.py install
# ë¹Œë“œ ì‹œê°„: 1-3ë¶„ ì†Œìš” (GPU ì•„í‚¤í…ì²˜ì— ë”°ë¼ ë‹¤ë¦„)

# 2. ì •í™•ì„± í…ŒìŠ¤íŠ¸
python3 test_correctness.py
# ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ PASSED ë˜ì–´ì•¼ í•¨

# 3. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
python3 profile_naive.py
# ì¶œë ¥: results/naive_metrics.json, results/naive_roofline.png
```

**ë¹Œë“œ ë¬¸ì œ í•´ê²°:**

ë§Œì•½ ë¹Œë“œê°€ ì‹¤íŒ¨í•˜ë©´:

```bash
# CUDA ê²½ë¡œ í™•ì¸
echo $CUDA_HOME

# ì—†ë‹¤ë©´ ì„¤ì •
export CUDA_HOME=/usr/local/cuda-12.4

# ë‹¤ì‹œ ë¹Œë“œ
python3 setup.py clean
python3 setup.py install
```

**ì˜ˆìƒ ì„±ëŠ¥:**
- PyTorch ëŒ€ë¹„ 0.5x ~ 1.5x (naive êµ¬í˜„ì´ë¯€ë¡œ ë” ëŠë¦´ ìˆ˜ ìˆìŒ)
- ì´ëŠ” ì •ìƒì´ë©°, ìµœì í™”ì˜ ì¶œë°œì ì…ë‹ˆë‹¤

### Phase 3: Tiled Implementation

```bash
cd ../phase3_tiled

# 1. CUDA extension ë¹Œë“œ
python3 setup.py install

# 2. ì •í™•ì„± í…ŒìŠ¤íŠ¸
python3 test_tiled.py
# ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ PASSED ë˜ì–´ì•¼ í•¨

# 3. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ (ì¶”ê°€ êµ¬í˜„ í•„ìš”)
# python3 profile_tiled.py
```

**ì˜ˆìƒ ì„±ëŠ¥:**
- Naive ëŒ€ë¹„ 1.5x ~ 3x í–¥ìƒ
- Shared memory ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ í–¥ìƒ

### Phase 4: Fused Kernel (Advanced)

```bash
cd ../phase4_optimized

# 1. CUDA extension ë¹Œë“œ
python3 setup.py install

# 2. í…ŒìŠ¤íŠ¸ ë° í”„ë¡œíŒŒì¼ë§ (êµ¬í˜„ í•„ìš”)
```

**ì˜ˆìƒ ì„±ëŠ¥:**
- Tiled ëŒ€ë¹„ 1.5x ~ 2x í–¥ìƒ
- Global memory traffic ìµœì†Œí™”

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì˜ˆì‹œ

ì¼ë°˜ì ì¸ êµ¬ì„± (batch=4, seq_len=128, head_dim=64):

| Implementation | Time (ms) | GFLOPS | Speedup |
|---------------|-----------|--------|---------|
| PyTorch       | 0.500     | 500    | 1.0x    |
| Naive CUDA    | 0.600     | 400    | 0.8x    |
| Tiled CUDA    | 0.300     | 800    | 1.7x    |
| Fused CUDA    | 0.200     | 1200   | 2.5x    |

*ì‹¤ì œ ì„±ëŠ¥ì€ GPU ëª¨ë¸ì— ë”°ë¼ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*

## í”„ë¡œíŒŒì¼ë§ with Nsight Compute

ë” ìì„¸í•œ ë¶„ì„ì„ ì›í•œë‹¤ë©´:

```bash
# ì „ì²´ í”„ë¡œíŒŒì¼ë§
ncu --set full --export profile_output python3 profile_pytorch.py

# íŠ¹ì • ë©”íŠ¸ë¦­ë§Œ
ncu --metrics sm__throughput.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed python3 profile_naive.py

# ê²°ê³¼ ë³´ê¸°
ncu-ui profile_output.ncu-rep
```

## ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: "nvcc: command not found"

```bash
# CUDA ì„¤ì¹˜ í™•ì¸
ls /usr/local/cuda-*/bin/nvcc

# ê²½ë¡œ ì„¤ì •
export PATH=/usr/local/cuda-12.4/bin:$PATH
```

### ë¬¸ì œ 2: "CUDA error: no kernel image available"

ì´ëŠ” GPUì˜ compute capabilityì™€ ì»´íŒŒì¼ëœ ì•„í‚¤í…ì²˜ê°€ ë§ì§€ ì•ŠëŠ” ê²½ìš°ì…ë‹ˆë‹¤.

```bash
# GPU compute capability í™•ì¸
python3 -c "import torch; print(torch.cuda.get_device_capability())"

# setup.pyì—ì„œ í•´ë‹¹ ì•„í‚¤í…ì²˜ ì¶”ê°€
# ì˜ˆ: compute capability 8.6 (RTX 3090) â†’ -arch=sm_86
```

### ë¬¸ì œ 3: PyTorch import ì˜¤ë¥˜

```bash
# PyTorch ì¬ì„¤ì¹˜
pip uninstall torch
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### ë¬¸ì œ 4: ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
# profile ìŠ¤í¬ë¦½íŠ¸ì—ì„œ batch_sizeë‚˜ seq_len ì¤„ì´ê¸°
```

## ë‹¤ìŒ ë‹¨ê³„

1. **Phaseë³„ ê²°ê³¼ ë¹„êµ**: ê° phaseì˜ metrics.json íŒŒì¼ì„ ë¹„êµí•˜ì—¬ ìµœì í™” íš¨ê³¼ í™•ì¸
2. **Roofline ë¶„ì„**: ê° êµ¬í˜„ì´ memory-boundì¸ì§€ compute-boundì¸ì§€ í™•ì¸
3. **íŒŒë¼ë¯¸í„° íŠœë‹**: tile_size ë“±ì˜ íŒŒë¼ë¯¸í„° ë³€ê²½í•˜ì—¬ ì„±ëŠ¥ ê°œì„  ì‹œë„
4. **ì‹¤ì œ ì‘ìš©**: ìì‹ ì˜ Transformer ëª¨ë¸ì— í†µí•©

## ì°¸ê³  ìë£Œ

- [CUDA C Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [PyTorch CUDA Extension](https://pytorch.org/tutorials/advanced/cpp_extension.html)
- [FlashAttention Paper](https://arxiv.org/abs/2205.14135)
- [Nsight Compute Documentation](https://docs.nvidia.com/nsight-compute/)

## ë„ì›€ì´ í•„ìš”í•œ ê²½ìš°

1. í”„ë¡œì íŠ¸ì˜ `readme.md` íŒŒì¼ì—ì„œ ìì„¸í•œ êµ¬í˜„ ê³„íš í™•ì¸
2. ê° phaseì˜ ì½”ë“œì— ìˆëŠ” ì£¼ì„ ì°¸ê³ 
3. GPU ëª¨ë¸ë³„ ìµœì í™” íŒì€ CUDA ë¬¸ì„œ ì°¸ì¡°

## í”„ë¡œì íŠ¸ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Phase 1: PyTorch baseline ì‹¤í–‰ ë° í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ
- [ ] Phase 2: Naive CUDA ë¹Œë“œ ë° ì •í™•ì„± ê²€ì¦ ì™„ë£Œ
- [ ] Phase 3: Tiled implementation ì •í™•ì„± ê²€ì¦ ì™„ë£Œ
- [ ] Phase 4: Fused kernel êµ¬í˜„ (ì„ íƒì‚¬í•­)
- [ ] ëª¨ë“  phaseì˜ Roofline ë¶„ì„ ì™„ë£Œ
- [ ] ì„±ëŠ¥ ë¹„êµ ë¬¸ì„œ ì‘ì„±

ì„±ê³µì ì¸ êµ¬í˜„ì„ ê¸°ì›í•©ë‹ˆë‹¤! ğŸš€
